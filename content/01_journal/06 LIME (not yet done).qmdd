---
title: "06 LIME"
author: "Prajwal Kumar,Koretagere Vijay Kumar"
date: "2023-05-15"

---
# Task

## This is a two part challenge:

### Part 1: Recreate plot_features(). Take the explanation data and use the first case to create a plot similar to the output of plot_features().

### Part 2: Recreate plot_explanations(): Take the full explanation data and recreate the second plot. (You will need at least the layers geom_tile() and facet_wrap())

---

```{r}
# LIME FEATURE EXPLANATION ----

# 1. Setup ----

# Load Libraries 
library(tidymodels)
library(magrittr)
library(dplyr)
library(sjmisc)
library(magrittr)
library(haven)
library(sjlabelled)
library(rsample)
library(recipes)
library(rstanarm)
library(broom.mixed)
library(h2o)
library(readxl)
library(tidyverse)
library(tidyquant)
library(lime)

```

```{r}
process_hr_data_readable <- function(data, definitions_tbl) {
  
  definitions_list <- definitions_tbl %>%
    fill(...1, .direction = "down") %>%
    filter(!is.na(...2)) %>%
    separate(...2, into = c("key", "value"), sep = " '", remove = TRUE) %>%
    rename(column_name = ...1) %>%
    mutate(key = as.numeric(key)) %>%
    mutate(value = value %>% str_replace(pattern = "'", replacement = "")) %>%
    split(.$column_name) %>%
    map(~ select(., -column_name)) %>%
    map(~ mutate(., value = as_factor(value))) 
  
  for (i in seq_along(definitions_list)) {
    list_name <- names(definitions_list)[i]
    colnames(definitions_list[[i]]) <- c(list_name, paste0(list_name, "_value"))
  }
  
  data_merged_tbl <- list(HR_Data = data) %>%
    append(definitions_list, after = 1) %>%
    reduce(left_join) %>%
    select(-one_of(names(definitions_list))) %>%
    set_names(str_replace_all(names(.), pattern = "_value", 
                              replacement = "")) %>%
    select(sort(names(.))) %>%
    mutate_if(is.character, as.factor) %>%
    mutate(
     
    )
  
  return(data_merged_tbl)
  
}

# Load Data
employee_attrition_tbl <- read_csv("../../WA_Fn-UseC_-HR-Employee-Attrition.csv")
definitions_raw_tbl    <- read_excel("../../data_definitions.xlsx", sheet = 1, col_names = FALSE)

# Processing Pipeline

employee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)

# Split into test and train
set.seed(seed = 1113)
split_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)

# Assign training and test data
train_readable_tbl <- training(split_obj)
test_readable_tbl  <- testing(split_obj)

# ML Preprocessing Recipe 
recipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%
  step_zv(all_predictors()) %>%
  step_mutate_at(c("JobLevel", "StockOptionLevel"), fn = as.factor) %>% 
  prep()

recipe_obj

train_tbl <- bake(recipe_obj, new_data = train_readable_tbl)
test_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)

```

```{r}


# 2. Models ----

h2o.init()
#h2o.getModel("metalearner_AUTO_StackedEnsemble_AllModels_1_AutoML_9_20220524_185544") %>% 
#  h2o.saveModel(path = "h20_models/")
automl_leader <- h2o.loadModel("../../content/01_journal/h20models/StackedEnsemble_AllModels_3_AutoML_2_20230517_140427")
automl_leader


```

```{r}

#3. LIME ----

# 3.1 Making Predictions ----

predictions_tbl <- automl_leader %>%
    h2o.predict(newdata = as.h2o(test_tbl)) %>%
    as_tibble() %>%
    bind_cols(
        test_tbl %>%
            select(EducationField)
    )

predictions_tbl
test_tbl %>%
  slice(1) %>%
  glimpse()

# 3.2 Single Explanation ----

explainer <- train_tbl %>%
  select(-Attrition) %>%
  lime(
    model           = automl_leader,
    bin_continuous  = TRUE,
    n_bins          = 4,
    quantile_bins   = TRUE
  )

explainer

?lime::explain

explanation <- test_tbl %>%
  slice(1) %>%
  select(-Attrition) %>%
  lime::explain(

    # Pass our explainer object
    explainer = explainer,
    # Because it is a binary classification model: 1
    n_labels   = 1,
    # number of features to be returned
    n_features = 8,
    # number of localized linear models
    n_permutations = 5000,
    # Let's start with 1
    kernel_width   = 1
  )

explanation

explanation %>%
  as.tibble() %>%
  select(feature:prediction)

g <- plot_features(explanation = explanation, ncol = 1)

plot_features(explanation = explanation, ncol = 1)

# 3.3 Multiple Explanations ----

explanation <- test_tbl %>%
  slice(1:20) %>%
  select(-Attrition) %>%
  lime::explain(
    explainer = explainer,
    n_labels   = 1,
    n_features = 8,
    n_permutations = 5000,
    kernel_width   = 0.5
  )

explanation %>%
  as.tibble()

plot_features(explanation, ncol = 4)

plot_explanations(explanation)
# Challenge part 1 ----
explanation %>%
  as.tibble()

case_1 <- explanation %>%
  filter(case == 1)

case_1 %>%
  plot_features()

case_1 %>%
  ggplot(aes(feature_weight, feature)) +
  geom_col(fill = "#1a2c50") +
  geom_smooth(method = "lm", se = FALSE) +
  scale_fill_manual(values = c("steelblue", "firebrick"), drop = FALSE) +
  labs(
    title = ("Model explanation"),
    x = "Weight",
    y = "Feature"
  ) +
  theme_tq_dark()

# Challenge part 2 ----
explanation %>% ggplot(aes_(~case, ~feature_desc)) +
  geom_tile(aes_(fill = ~feature_weight)) +
  scale_x_discrete("Case", expand = c(0, 0)) +
  scale_y_discrete("Feature", expand = c(0, 0)) +
  scale_fill_gradient2("Feature\nweight", low = "firebrick", mid = "#f7f7f7", high = "steelblue") +
  theme(panel.border = element_rect(fill = NA,
                                    colour = "grey60",
                                    size = 1),
        panel.grid = element_blank(),
        legend.position = "right",
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  facet_wrap(~label)

```